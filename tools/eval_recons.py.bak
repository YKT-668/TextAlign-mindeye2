#!/usr/bin/env python
import argparse, os, json, math
import torch
import torch.nn.functional as F

def cosine_sim(a, b):
    a = F.normalize(a, dim=-1)
    b = F.normalize(b, dim=-1)
    return a @ b.t()

def topk_acc(scores, gt_indices, k=1):
    if len(gt_indices)==0: return float("nan")
    correct = 0; total = 0
    topk = torch.topk(scores, k, dim=1).indices  # [N,k]
    for i, gi in enumerate(gt_indices):
        if gi < 0: continue
        total += 1
        if gi in topk[i].tolist():
            correct += 1
    return (correct / total) if total>0 else float("nan")

def try_load(path):
    if not os.path.isfile(path):
        raise FileNotFoundError(path)
    # 先用默认（torch>=2.6 默认 weights_only=True）
    try:
        return torch.load(path, map_location="cpu")
    except Exception:
        # 老式 pickle：增加白名单并关掉 weights_only
        import numpy as np
        from torch.serialization import add_safe_globals
        add_safe_globals([np.core.multiarray._reconstruct])
        return torch.load(path, map_location="cpu", weights_only=False)

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--model_dir", required=True, help=".../train_logs/<model>")
    ap.add_argument("--gt_images", required=True, help="GT 图像在同一 CLIP 空间的嵌入 [M,D]")
    ap.add_argument("--gt_captions", default="", help="可选：caption 向量/对象；加载失败将忽略")
    ap.add_argument("--calc_mse", action="store_true")
    ap.add_argument("--calc_lpips", action="store_true")
    args = ap.parse_args()

    infer = os.path.join(args.model_dir, "inference")
    recons_pt = os.path.join(infer, "recons.pt")
    ids_json  = os.path.join(infer, "ids.json")
    metrics_json = os.path.join(args.model_dir, "metrics.json")

    recons = try_load(recons_pt)            # [N,D]
    all_images = try_load(args.gt_images)   # [M,D]（若不是嵌入会在前置步骤处理）
    if all_images.ndim != 2:
        raise SystemExit("[eval] all_images 需要是 [M,D] 嵌入；请先用与 recons 相同的 CLIP 编码。")

    # captions 可选加载；失败直接忽略
    if args.gt_captions:
        try:
            _ = try_load(args.gt_captions)
        except Exception as e:
            print("[eval] WARN: skip loading captions:", e)

    # 解析 gt 索引
    if os.path.isfile(ids_json):
        ids = json.load(open(ids_json))
        gt_idx = [int(i) if isinstance(i, int) else -1 for i in ids]
        if len(gt_idx) != recons.shape[0]:
            n = min(len(gt_idx), recons.shape[0])
            recons = recons[:n]
            gt_idx = gt_idx[:n]
    else:
        gt_idx = [-1] * recons.shape[0]

    # 相似度与检索
    sim = cosine_sim(recons, all_images)  # [N,M]
    if all(i>=0 for i in gt_idx):
        # 有完整对齐：用对应 GT 的余弦
        mean_cos = float((F.normalize(recons, -1) * F.normalize(all_images[gt_idx], -1)).sum(-1).mean().item())
    else:
        # 没对齐：用最近邻相似度的平均作近似
        mean_cos = float(torch.max(sim, dim=1).values.mean().item())

    top1 = topk_acc(sim, gt_idx, k=1)
    top5 = topk_acc(sim, gt_idx, k=5)

    mse = None
    lpips_v = None
    if args.calc_mse or args.calc_lpips:
        print("[eval] NOTE: MSE/LPIPS 需要像素级 GT 与重建像素，默认不算。有需要我再补像素对齐评估。")

    metrics = {
        "model_dir": args.model_dir,
        "top1_new": None if math.isnan(top1) else top1,
        "top5_new": None if math.isnan(top5) else top5,
        "clip_cosine": mean_cos,
        "mse": mse,
        "lpips": lpips_v,
        "set": "new_test",
    }
    with open(metrics_json, "w") as f:
        json.dump(metrics, f, indent=2, ensure_ascii=False)
    print("[eval] wrote:", metrics_json, metrics)

if __name__ == "__main__":
    main()
