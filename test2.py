'''æŠŠ â€œå®˜æ–¹çš„ Priorâ€ ç§»æ¤åˆ°ä½  â€œä¿®å¥½çš„æ¨¡å‹â€ ä¸Šï¼Œåˆæˆä¸€ä¸ªå®Œç¾çš„ Frankenstein (ç¼åˆæ€ª)ã€‚

åŸæ–™ 1ï¼šå®˜æ–¹ Checkpoint (æœ‰å¥½çš„ Priorï¼Œä½† Ridge æ˜¯é”™çš„)ã€‚

åŸæ–™ 2ï¼šä½ çš„ Repair Checkpoint (æœ‰ä¿®å¥½çš„ Ridge/Backbone/Headï¼Œä½†æ²¡æœ‰ Prior)ã€‚

æ‰‹æœ¯ï¼šæŠŠ 1 çš„ Prior æŒ–å‡ºæ¥ï¼Œå¡è¿› 2 é‡Œã€‚'''

import torch
import os

# 1. å®šä¹‰è·¯å¾„
path_official = '/mnt/work/repos/mindeyev2_ckpts/train_logs/final_multisubject_subj01/last.pth'
path_repair   = '/mnt/work/repos/TextAlign-mindeye2/train_logs/s1_textalign_stage0_repair_80G/last.pth'
path_out      = '/mnt/work/repos/TextAlign-mindeye2/train_logs/merged_stage0_for_stage1.pth'

print('ğŸ’‰ å¼€å§‹è¿›è¡Œæƒé‡æ‰‹æœ¯...')

# 2. åŠ è½½ä¸¤ä¸ªæ¨¡å‹
print(f'Loading Official: {path_official}')
sd_off = torch.load(path_official, map_location='cpu')
# å¤„ç†åµŒå¥—
if 'state_dict' in sd_off: sd_off = sd_off['state_dict']
elif 'model' in sd_off: sd_off = sd_off['model']

print(f'Loading Repair:   {path_repair}')
sd_rep = torch.load(path_repair, map_location='cpu')
if 'state_dict' in sd_rep: sd_rep = sd_rep['state_dict']
elif 'model' in sd_rep: sd_rep = sd_rep['model']

# 3. ç§»æ¤æ‰‹æœ¯
# ä»¥ Repair ä¸ºåº•åº§ï¼ˆå› ä¸ºå®ƒæœ‰æ­£ç¡®çš„ Ridge å’Œ Headï¼‰
sd_final = sd_rep.copy()
count = 0

print('ğŸ” æ­£åœ¨å¯»æ‰¾å¹¶ç§»æ¤ Prior æƒé‡...')
for key, val in sd_off.items():
    # åªè¦æ˜¯ diffusion_prior ç›¸å…³çš„æƒé‡ï¼Œå…¨éƒ¨ä»å®˜æ–¹è¦†ç›–è¿‡æ¥
    if 'prior' in key or 'diffusion' in key:
        sd_final[key] = val
        count += 1

print(f'âœ… æˆåŠŸç§»æ¤äº† {count} ä¸ª Prior å±‚æƒé‡ï¼')

# 4. ä¿å­˜
torch.save(sd_final, path_out)
print(f'ğŸ’¾ åˆæˆæ¨¡å‹å·²ä¿å­˜è‡³: {path_out}')
print('ğŸš€ ç°åœ¨ä½ å¯ä»¥ç”¨è¿™ä¸ªæ–‡ä»¶è·‘ Stage 1 äº†ï¼')
