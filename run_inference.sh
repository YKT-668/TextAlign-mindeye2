#!/bin/bash

# ======================================================================================
# MindEyeV2 - å®Œæ•´æ¨ç†æµç¨‹æ€»æ§è„šæœ¬ (run_inference.sh) - v2.4 (subj01+trainæŠ•å½±+PEFTç‰ˆ)
#
# è®¾è®¡å“²å­¦:
#   æœ¬è„šæœ¬æ˜¯ä¸€ä¸ªçœŸæ­£çš„ç«¯åˆ°ç«¯æ¨ç†æµæ°´çº¿ã€‚å®ƒæ¥æ”¶åŸå§‹è¾“å…¥ï¼Œé€šè¿‡ä¸€ç³»åˆ—æ¨¡å—åŒ–
#   æ­¥éª¤å¤„ç†ï¼Œæœ€ç»ˆç”Ÿæˆè¾“å‡ºã€‚åŒæ—¶ï¼Œå®ƒä¹Ÿæ”¯æŒæ–­ç‚¹ç»­ä¼ ä»¥æ–¹ä¾¿è°ƒè¯•ã€‚
#
# æ–°å¢/å½“å‰åŠŸèƒ½:
#   - ä½¿ç”¨å®˜æ–¹ subj01 40sess é¢„è®­ç»ƒæ¨¡å‹åš fMRIâ†’CLIP-image å‘é‡è§£ç 
#   - ä½¿ç”¨ä½ åŸºäº subj01 è®­ç»ƒé›† (9000 å›¾åƒ) è®­ç»ƒå¥½çš„ brainâ†’ViT-H æŠ•å½±çŸ©é˜µ
#   - å¯é€‰ RAG + LLM èåˆ Top-K captionï¼Œå›é€€ä¸ºæœ¬åœ°ç®€å•èåˆ
#   - ç»Ÿä¸€ç”¨ gen_sdxl_with_peft.py å®Œæˆ SDXL+IP-Adapter+PEFT ç”Ÿæˆ
#   - å¯é€‰ PEFT ä¸ªæ€§åŒ–é€‚é…å™¨ (train_logs/peft_adapter_subj01)
#   - æ˜¾å­˜ä¼˜åŒ–å¼€å…³ ENABLE_CPU_OFFLOAD
#   - PREP_OFFICIAL_PROJ=1ï¼šä»…åšâ€œå®˜æ–¹ç‰¹å¾+å®˜æ–¹ç‰ˆæŠ•å½±çŸ©é˜µâ€å‡†å¤‡ï¼ˆè¾“å‡ºåˆ° *_official.ptï¼‰
# ======================================================================================

# --- è„šæœ¬å¥å£®æ€§è®¾ç½® ---
set -eo pipefail

# --- æ¨ç†å¿…é¡»ä½¿ç”¨ mindeye21 ç¯å¢ƒ ---
PY_INFER="/home/vipuser/miniconda3/envs/mindeye21/bin/python"
if [[ ! -x "$PY_INFER" ]]; then
    echo "âŒ æ‰¾ä¸åˆ° mindeye ç¯å¢ƒ Python: $PY_INFER" >&2
    exit 1
fi

# ä»ç„¶å…è®¸åŠ è½½ .bashrc ä»¥è·å– API keys ç­‰
if [ -f ~/.bashrc ]; then
    source ~/.bashrc
fi

# ======================================================================================
# Â§1. å¯é…ç½®å‚æ•°
# ======================================================================================

# --- æ ¸å¿ƒæ ‡è¯†ç¬¦ ---
export EXP_NAME="subj01_inference_run_final"
export SUBJ_ID=1

# --- æ˜¾å­˜ä¼˜åŒ–å’Œ PEFT å¼€å…³ ---
# é‡åˆ° CUDA OOM å¯è®¾ä¸º true
export ENABLE_CPU_OFFLOAD=false

# [é‡è¦] PEFTé€‚é…å™¨ç›®å½•ï¼ˆè½¯prompt/LoRAï¼‰ã€‚å¦‚æœä¸æƒ³ä½¿ç”¨ï¼Œä¿æŒä¸ºç©ºå­—ç¬¦ä¸² ""
# è§„åˆ™ï¼š
#  1) è‹¥å¤–éƒ¨å·²é€šè¿‡ç¯å¢ƒå˜é‡ PEFT_ADAPTER_DIR æä¾›ï¼Œåˆ™ä¸¥æ ¼ä½¿ç”¨è¯¥å€¼ï¼›
#  2) å¦åˆ™ï¼Œé»˜è®¤å°è¯•ä½¿ç”¨ ${PROJ_ROOT}/train_logs/peft_adapter_subj%02dï¼ˆæŒ‰ SUBJ_ID è¡¥é›¶ï¼‰ï¼Œè‹¥ä¸å­˜åœ¨åˆ™ç½®ç©ºã€‚
export PEFT_ADAPTER_DIR="${PEFT_ADAPTER_DIR:-}"

# --- è·¯å¾„é…ç½® ---
SCRIPT_DIR=$(cd -- "$(dirname -- "${BASH_SOURCE[0]}")" &> /dev/null && pwd)
export PROJ_ROOT="$SCRIPT_DIR" # å‡è®¾è„šæœ¬æ”¾åœ¨ MindEyeV2_Project ç›®å½•ä¸‹

# å¦‚æœæœªæ˜¾å¼æŒ‡å®š PEFT_ADAPTER_DIRï¼Œåˆ™æ ¹æ® SUBJ_ID è®¾é»˜è®¤ç›®å½•
if [ -z "${PEFT_ADAPTER_DIR}" ]; then
    subj_pad=$(printf "%02d" "${SUBJ_ID}")
    candidate="${PROJ_ROOT}/train_logs/peft_adapter_subj${subj_pad}"
    if [ -d "$candidate" ] || [ -f "${candidate}/soft_tokens.pt" ]; then
        export PEFT_ADAPTER_DIR="$candidate"
    else
        export PEFT_ADAPTER_DIR=""
    fi
fi

# NSD æ•°æ®è·¯å¾„ï¼ˆå¦‚æœè®­ç»ƒæ—¶åšäº† ds_viewï¼Œä¼šåœ¨åé¢è‡ªåŠ¨è¦†ç›–ï¼‰
export NSD_DATA_PATH="/home/vipuser/MindEyeV2_Project/src"

# ä½¿ç”¨å®˜æ–¹ subj01 40sess å®Œæ•´æ¨¡å‹ä½œä¸º fMRI â†’ CLIP ç¼–ç å™¨
export MINDYEYE_MODEL_NAME="${MINDYEYE_MODEL_NAME:-final_subj01_pretrained_40sess_24bs}"

# å…è®¸é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–è¾“å‡ºæ ¹ç›®å½•ï¼Œå¦åˆ™é»˜è®¤å†™åˆ°é¡¹ç›®å†… runs/
# ç¤ºä¾‹ï¼šOUTPUT_ROOT=/mnt/mindeye_data/mindeye_runs bash run_inference.sh
export OUTPUT_ROOT="${OUTPUT_ROOT:-${PROJ_ROOT}/runs}"
export EXP_DIR="${OUTPUT_ROOT}/${EXP_NAME}"

# ç»Ÿä¸€ç¼“å­˜è·¯å¾„ï¼ˆæ”¯æŒè¦†ç›– CACHE_ROOTï¼Œå°†ç¼“å­˜æŒ‡åˆ°å¤§ç›˜ä»¥é¿å…å†™æ»¡ï¼‰
# ç¤ºä¾‹ï¼šCACHE_ROOT=/mnt/mindeye_data/mindeye_cache bash run_inference.sh
export CACHE_ROOT="${CACHE_ROOT:-${PROJ_ROOT}/cache}"
export HF_HOME="${CACHE_ROOT}/hf_home"
export HUGGINGFACE_HUB_CACHE="${CACHE_ROOT}/hub"
export TRANSFORMERS_CACHE="${CACHE_ROOT}/hub"
export TORCH_HOME="${CACHE_ROOT}/models"

mkdir -p "$HF_HOME" "$HUGGINGFACE_HUB_CACHE" "$TORCH_HOME" || true

# ä½¿ç”¨é•œåƒåŠ é€Ÿ/å›é€€ Hugging Face ä¸‹è½½ï¼ˆå¯è¢«ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
export HF_ENDPOINT="https://hf-mirror.com"

# --- RAG & LLM é…ç½® ---
# ä½¿ç”¨æ‰©å»ºåçš„ COCO å…¨é‡ RAG çŸ¥è¯†åº“ä½œä¸ºé»˜è®¤
export TEXT_INDEX_PT="${PROJ_ROOT}/data/coco_full_index.pt"
export ALL_CAPTIONS_PT="${PROJ_ROOT}/data/coco_full_captions.pt"
export TOP_K=16

# --- å›¾åƒç”Ÿæˆé…ç½® ---
export IP_ADAPTER_DIR="/home/vipuser/models/IP-Adapter" # IP-Adapter æ¨¡å‹æ ¹ç›®å½•

# â˜… å½“å‰ä¸»çº¿ä½¿ç”¨ï¼šåŸºäº subj01 è®­ç»ƒé›†è®­ç»ƒå¥½çš„ brainâ†’ViT-H æŠ•å½±çŸ©é˜µ
#   ä½ åˆšåˆšè·‘çš„æ˜¯:
#   python tools/train_brain2vith.py \
#       --brain_pt data/proj_subj01_train/all_subjects_brain_vectors.pt \
#       --img_vith_pt data/proj_subj01_train/all_subjects_gt_vith.pt \
#       --out checkpoints/brain2vith_subj01_train.pt
export PROJECTION_MATRIX_PT="${PROJ_ROOT}/checkpoints/brain2vith_subj01_l2_1e3.pt"


export GEN_STEPS=30
export GEN_CFG=5.0
# å¯é€‰: é™åˆ¶ç”Ÿæˆçš„å‰Né¡¹ã€‚è‹¥å¤–éƒ¨æœªæä¾›åˆ™é»˜è®¤ä¸é™åˆ¶ã€‚
export GEN_LIMIT="${GEN_LIMIT:-}"
# ç”Ÿæˆåˆ†è¾¨ç‡
export GEN_W=${GEN_W:-768}
export GEN_H=${GEN_H:-768}

# --- è¯„æµ‹é…ç½® ---
# å®˜æ–¹æä¾›çš„ 73k å›¾åƒç‰¹å¾ï¼Œç”¨äºè¯„æµ‹é‡å»ºæ•ˆæœ
export GT_EMBEDS_PT="${PROJ_ROOT}/evals/all_images.pt"

# --- å®˜æ–¹ subj æ¨¡å‹çš„ä¸€é”®å‡†å¤‡æ¨¡å¼ï¼šæå–ç‰¹å¾ + è®­ç»ƒâ€œå®˜æ–¹ç‰ˆâ€ brainâ†’ViT-H æŠ•å½±çŸ©é˜µ ---
# ä½¿ç”¨æ–¹å¼ï¼š
#   PREP_OFFICIAL_PROJ=1 bash run_inference.sh
# è¡Œä¸ºï¼š
#   - åªç”¨å®˜æ–¹ MindEye2 â†’ æå– subj çš„ 982 å›¾åƒç‰¹å¾
#   - è®­ç»ƒä¸€ä¸ªâ€œå®˜æ–¹ç‰ˆâ€æŠ•å½±çŸ©é˜µï¼Œè¾“å‡ºåˆ° checkpoints/brain2vith_subjXX_official.pt
#   - ä¸å½±å“ä¸»çº¿ç”¨çš„ checkpoints/brain2vith_subj01_train.pt
export PREP_OFFICIAL_PROJ="${PREP_OFFICIAL_PROJ:-0}"

if [[ "${PREP_OFFICIAL_PROJ}" == "1" ]]; then
    echo "============================================================"
    echo "Â§OFF.0 å®˜æ–¹ MindEye2 subj${SUBJ_ID} æŠ•å½±çŸ©é˜µå‡†å¤‡ (official 982 å›¾åƒç‰ˆ)"
    echo "============================================================"

    subj_pad=$(printf "%02d" "${SUBJ_ID}")
    PROJ_DATA_DIR="${PROJ_ROOT}/data/proj_subj${subj_pad}"
    mkdir -p "${PROJ_DATA_DIR}"

    # å®˜æ–¹æ¨¡å‹è·¯å¾„
    PROJ_BASE_MODEL_DIR="${PROJ_ROOT}/train_logs/${MINDYEYE_MODEL_NAME}"
    if [[ ! -f "${PROJ_BASE_MODEL_DIR}/last.pth" ]]; then
        echo "âŒ æ‰¾ä¸åˆ°æ¨¡å‹æƒé‡: ${PROJ_BASE_MODEL_DIR}/last.pth" >&2
        echo "   è¯·ç¡®è®¤å·²ä¸‹è½½ Hugging Face ä¸Šçš„ ${MINDYEYE_MODEL_NAME}/last.pth" >&2
        exit 1
    fi

    echo "--- OFF.1 æå– subj${SUBJ_ID} çš„ brain / ViT-H ç‰¹å¾ (å®˜æ–¹ preset) ---"
    "${PY_INFER}" "${PROJ_ROOT}/tools/extract_all_features.py" \
        --mindeye_model_dir "${PROJ_BASE_MODEL_DIR}" \
        --out_dir "${PROJ_DATA_DIR}" \
        --data_path "${NSD_DATA_PATH}" \
        --device "cuda" \
        --subjects "${SUBJ_ID}"

    BRAIN_PT="${PROJ_DATA_DIR}/all_subjects_brain_vectors.pt"
    IMG_PT="${PROJ_DATA_DIR}/all_subjects_gt_vith.pt"

    if [[ ! -f "${BRAIN_PT}" || ! -f "${IMG_PT}" ]]; then
        echo "âŒ æå–ç‰¹å¾å¤±è´¥ï¼Œæœªæ‰¾åˆ°æœŸæœ›çš„è¾“å‡ºæ–‡ä»¶ï¼š" >&2
        echo "   - ${BRAIN_PT}" >&2
        echo "   - ${IMG_PT}" >&2
        exit 1
    fi

    # å®˜æ–¹ç‰ˆæŠ•å½±çŸ©é˜µå•ç‹¬è¾“å‡ºï¼Œé¿å…è¦†ç›– train ç‰ˆ
    OFFICIAL_PROJECTION_MATRIX_PT="${PROJ_ROOT}/checkpoints/brain2vith_subj${subj_pad}_official.pt"

    echo "--- OFF.2 è®­ç»ƒ subj${SUBJ_ID} çš„å®˜æ–¹ç‰ˆ brainâ†’ViT-H çº¿æ€§æŠ•å½± ---"
    "${PY_INFER}" "${PROJ_ROOT}/tools/train_brain2vith.py" \
        --brain_pt "${BRAIN_PT}" \
        --img_vith_pt "${IMG_PT}" \
        --out "${OFFICIAL_PROJECTION_MATRIX_PT}" \
        --mode "closed_form" \
        --lambda_l2 1e-3 \
        --device "cuda"

    if [[ -f "${OFFICIAL_PROJECTION_MATRIX_PT}" ]]; then
        echo "âœ… subj${SUBJ_ID} å®˜æ–¹ç‰ˆæŠ•å½±çŸ©é˜µå·²å†™å…¥: ${OFFICIAL_PROJECTION_MATRIX_PT}"
        echo "âœ¨ å®˜æ–¹å‡†å¤‡æ¨¡å¼å®Œæˆï¼ˆPREP_OFFICIAL_PROJ=1ï¼‰ï¼Œä¸è¿›å…¥å®Œæ•´æ¨ç†æµç¨‹ã€‚"
        exit 0
    else
        echo "âŒ æŠ•å½±çŸ©é˜µè®­ç»ƒåæœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶: ${OFFICIAL_PROJECTION_MATRIX_PT}" >&2
        exit 1
    fi
fi

# ======================================================================================
# Â§2. è„šæœ¬ä¸»é€»è¾‘
# ======================================================================================

echo "============================================================"
echo "Â§0. åˆå§‹åŒ–å®éªŒ: ${EXP_NAME}"
echo "============================================================"

TOTAL_START_TIME=$(date +%s)
declare -A STEP_TIMES
declare -a STEP_NAMES

# è§£æ --force å‚æ•°
FORCE_RUN=false
if [[ "$1" == "--force" ]]; then
    FORCE_RUN=true
    echo "ğŸŸ¡ æ£€æµ‹åˆ° --force æ ‡å¿—ï¼Œå°†å¼ºåˆ¶é‡æ–°è¿è¡Œæ‰€æœ‰æ­¥éª¤ã€‚"
    if [ -d "$EXP_DIR" ]; then
        echo "   æ­£åœ¨æ¸…ç©ºæ—§çš„å®éªŒç›®å½•: ${EXP_DIR}"
        rm -rf "${EXP_DIR}"
    fi
fi

# æ£€æŸ¥å…³é”®ç¯å¢ƒå˜é‡/æ–‡ä»¶
if [ -z "$DEEPSEEK_API_KEY" ]; then
    echo "ğŸŸ¡ è­¦å‘Š: DEEPSEEK_API_KEY æœªè®¾ç½®ï¼Œå°†ä½¿ç”¨æœ¬åœ°å›é€€ç­–ç•¥ç”Ÿæˆæç¤ºã€‚"
else
    echo "âœ… DEEPSEEK_API_KEY å·²æ£€æµ‹åˆ°ï¼Œå°†å°è¯•ä½¿ç”¨ DeepSeek ç”Ÿæˆç»“æ„åŒ–æç¤ºã€‚"
fi

if [ ! -f "$TEXT_INDEX_PT" ]; then
    echo "âŒ é”™è¯¯: RAG æ–‡æœ¬ç‰¹å¾ç´¢å¼•æœªæ‰¾åˆ°: ${TEXT_INDEX_PT}" >&2
    exit 1
fi
if [ ! -f "$PROJECTION_MATRIX_PT" ]; then
    echo "âŒ é”™è¯¯: æŠ•å½±çŸ©é˜µæœªæ‰¾åˆ°: ${PROJECTION_MATRIX_PT}" >&2
    echo "   è¯·ç¡®è®¤å·²è®­ç»ƒ: checkpoints/brain2vith_subj01_train.pt" >&2
    exit 1
fi

mkdir -p "${EXP_DIR}/decoded_features" "${EXP_DIR}/retrieved_texts" "${EXP_DIR}/llm_prompts" "${EXP_DIR}/generated_images" "${EXP_DIR}/eval_results"
echo "âœ… å®éªŒç›®å½•å·²å°±ç»ª: ${EXP_DIR}"
echo ""

echo "[cfg] ENABLE_CPU_OFFLOAD=${ENABLE_CPU_OFFLOAD}"
echo "[cfg] PEFT_ADAPTER_DIR=${PEFT_ADAPTER_DIR:-<empty>}"

# è¾…åŠ©å‡½æ•°
run_step() {
    local step_name="$1"
    local output_file="$2"
    shift 2
    local command=("$@")
    
    local step_start_time=$(date +%s)
    local step_key=$(echo "$step_name" | sed 's/.*Â§\([0-9]\+\.[0-9]\+\|[0-9]\+\)\./\1/')

    echo "============================================================"
    echo "$step_name"
    echo "============================================================"

    local output_exists=false
    if [[ -f "$output_file" ]] || [[ -d "$output_file" && -n "$(ls -A "$output_file" 2>/dev/null)" ]]; then
        output_exists=true
    fi

    if [[ "$FORCE_RUN" == "false" && "$output_exists" == "true" ]]; then
        echo "ğŸŸ¡ è¾“å‡ºå·²å­˜åœ¨ï¼Œè·³è¿‡æ­¤æ­¥éª¤ã€‚ä½¿ç”¨ --force å¼ºåˆ¶é‡æ–°è¿è¡Œã€‚"
        echo "   - è·¯å¾„: ${output_file}"
        STEP_TIMES["$step_key"]=0
        STEP_NAMES+=("$step_name")
    else
        echo "ğŸš€ æ­£åœ¨æ‰§è¡Œå‘½ä»¤..."
        eval "${command[@]}"
        
        local output_exists_after=false
        if [[ -f "$output_file" || -d "$output_file" ]]; then
            output_exists_after=true
        fi

        if [ $? -eq 0 ] && [ "$output_exists_after" == "true" ]; then
            echo "âœ… æ­¥éª¤æˆåŠŸå®Œæˆã€‚"
        else
            echo "âŒ é”™è¯¯: æ­¥éª¤æ‰§è¡Œå¤±è´¥æˆ–æœªç”Ÿæˆé¢„æœŸçš„è¾“å‡ºã€‚" >&2
            echo "   - å¤±è´¥çš„å‘½ä»¤: ${command[@]}" >&2
            echo "   - é¢„æœŸçš„è¾“å‡º: ${output_file}" >&2
            exit 1
        fi
        
        local step_end_time=$(date +%s)
        local step_duration=$((step_end_time - step_start_time))
        STEP_TIMES["$step_key"]=$step_duration
        STEP_NAMES+=("$step_name")
        
        echo "â±ï¸  æ­¥éª¤ç”¨æ—¶: ${step_duration}ç§’"
    fi
    echo ""
}

# è‹¥è®­ç»ƒæ—¶åšäº† subj01 è§†å›¾åˆ’åˆ†ï¼Œåˆ™æ²¿ç”¨è¯¥è§†å›¾çš„æ•°æ®è·¯å¾„
MODEL_DIR="${PROJ_ROOT}/train_logs/${MINDYEYE_MODEL_NAME}"
if [[ -d "${MODEL_DIR}/ds_view/wds/subj01/new_test" ]] && [[ -f "${MODEL_DIR}/ds_view/wds/subj01/new_test/0.tar" ]]; then
    export NSD_DATA_PATH="${MODEL_DIR}/ds_view"
    echo "ğŸŸ¡ ä½¿ç”¨è®­ç»ƒè§†å›¾æ•°æ®è·¯å¾„: ${NSD_DATA_PATH}"
fi

# è‹¥éœ€è¦ç­‰å¾… last.pthï¼Œå¯è®¾ WAIT_FOR_LAST=1
if [[ "${WAIT_FOR_LAST:-0}" == "1" ]]; then
    CKPT_PATH="${MODEL_DIR}/last.pth"
    echo "ğŸ•’ WAIT_FOR_LAST=1: ç­‰å¾…æ¨¡å‹æƒé‡: ${CKPT_PATH}"
    while [[ ! -f "$CKPT_PATH" ]]; do sleep 30; done
    echo "âœ… æ£€æµ‹åˆ°æ¨¡å‹: $CKPT_PATH"
fi

# --- å®šä¹‰æ‰€æœ‰ä¸­é—´æ–‡ä»¶è·¯å¾„ ---
BRAIN_VEC_PT="${EXP_DIR}/decoded_features/brain_clip_vectors.pt"
BRAIN_IDS_JSON="${EXP_DIR}/decoded_features/brain_clip_ids.json"
TOPK_JSONL="${EXP_DIR}/retrieved_texts/topk_texts.jsonl"
LLM_PROMPTS_JSON="${EXP_DIR}/llm_prompts/structured_prompts.json"
GEN_IMAGES_DIR="${EXP_DIR}/generated_images"
RECONS_PT="${EXP_DIR}/eval_results/recons_features.pt"
METRICS_JSON="${EXP_DIR}/eval_results/metrics.json"

# --- Â§1 fMRI â†’ CLIP-image å‘é‡ ---
CMD_STEP1="${PY_INFER} \"${PROJ_ROOT}/src/extract_clip_vectors.py\" \
    --model_name \"$MINDYEYE_MODEL_NAME\" \
    --data_path \"$NSD_DATA_PATH\" \
    --subj \"$SUBJ_ID\" \
    --clip_out \"$BRAIN_VEC_PT\" \
    --ids_out \"$BRAIN_IDS_JSON\""
run_step "Â§1. fMRIè§£ç " "$BRAIN_VEC_PT" "$CMD_STEP1"

# --- Â§2 RAG Top-K æ£€ç´¢ ---
CMD_STEP2="${PY_INFER} \"${PROJ_ROOT}/tools/retrieve_topk.py\" \
    --brain_vec_pt \"$BRAIN_VEC_PT\" \
    --text_index_pt \"$TEXT_INDEX_PT\" \
    --ids_json \"$BRAIN_IDS_JSON\" \
    --captions_pt \"$ALL_CAPTIONS_PT\" \
    --out_jsonl \"$TOPK_JSONL\" \
    --topk \"$TOP_K\""
run_step "Â§2. RAGæ£€ç´¢" "$TOPK_JSONL" "$CMD_STEP2"

# --- Â§3 LLM èåˆæˆç»“æ„åŒ–æç¤ºï¼ˆå¸¦å›é€€ï¼‰ ---
step3_start_time=$(date +%s)

echo "============================================================"
echo "Â§3. LLMèåˆ: Top-K æ–‡æœ¬ â†’ ç»“æ„åŒ–æç¤º"
echo "============================================================"
echo "ğŸš€ å°è¯•ä½¿ç”¨ DeepSeek ç”Ÿæˆç»“æ„åŒ–æç¤ºï¼ˆå¦‚æœé…ç½®äº† API Keyï¼‰..."

CMD_STEP3="${PY_INFER} \"${PROJ_ROOT}/tools/prompts_from_topk_llm.py\" \
    --topk_jsonl \"$TOPK_JSONL\" \
    --out_json \"$LLM_PROMPTS_JSON\" \
    --max_workers 16 \
    --batch_size 100"

set +e
eval "$CMD_STEP3"
ret=$?
set -e

need_fallback=false
if [ ! -f "$LLM_PROMPTS_JSON" ]; then
    need_fallback=true
else
    num_prompts=$("$PY_INFER" - <<PY
import json
try:
    j=json.load(open(r"$LLM_PROMPTS_JSON"))
    print(len(j) if isinstance(j,list) else 0)
except Exception:
    print(0)
PY
)
    if [ "$num_prompts" -eq 0 ]; then
        need_fallback=true
    fi
fi

if [ "$need_fallback" = true ]; then
    echo "ğŸŸ¡ LLM æœªç”Ÿæˆæç¤ºæˆ–å¤±è´¥ï¼ˆexit code=${ret}ï¼‰ï¼Œä½¿ç”¨ Top-K æ–‡æœ¬å›é€€ç”Ÿæˆç®€å•æç¤ºã€‚"
    "$PY_INFER" - <<PY
import json
topk_path=r"$TOPK_JSONL"
out_path=r"$LLM_PROMPTS_JSON"
prompts=[]
with open(topk_path,'r',encoding='utf-8') as f:
    for line in f:
        if not line.strip():
            continue
        rec=json.loads(line)
        topk=rec.get('topk',[])
        if not topk:
            continue
        positive='; '.join(topk[:5])
        prompts.append({
            'id': rec.get('id'),
            'positive': positive,
            'negative': 'blurry, low quality, artifacts, extra limbs, text, watermark'
        })
json.dump(prompts, open(out_path,'w',encoding='utf-8'),
          ensure_ascii=False, indent=2)
print('wrote', out_path, len(prompts))
PY
else
    echo "âœ… LLM å·²ç”Ÿæˆç»“æ„åŒ–æç¤º: $LLM_PROMPTS_JSON"
fi

step3_end_time=$(date +%s)
step3_duration=$((step3_end_time - step3_start_time))
STEP_TIMES["3"]=$step3_duration
STEP_NAMES+=("Â§3. LLMèåˆ: Top-K æ–‡æœ¬ â†’ ç»“æ„åŒ–æç¤º")
echo "â±ï¸  æ­¥éª¤ç”¨æ—¶: ${step3_duration}ç§’"
echo ""

# --- Â§4 SDXL + IP-Adapter(+PEFT) ç”Ÿæˆå›¾åƒ ---
CMD_STEP4="${PY_INFER} \"${PROJ_ROOT}/tools/gen_sdxl_with_peft.py\" \
    --adapter_dir \"$IP_ADAPTER_DIR\" \
    --prompts \"$LLM_PROMPTS_JSON\" \
    --brain_vec_pt \"$BRAIN_VEC_PT\" \
    --proj_pt \"$PROJECTION_MATRIX_PT\" \
    --peft_adapter_dir \"$PEFT_ADAPTER_DIR\" \
    --out_dir \"$GEN_IMAGES_DIR\" \
    --steps \"$GEN_STEPS\" \
    --cfg \"$GEN_CFG\" \
    --w \"$GEN_W\" \
    --h \"$GEN_H\" \
    --dtype fp16 \
    --ip_scale 0.8"

if [ "$ENABLE_CPU_OFFLOAD" = true ]; then
    echo "ğŸŸ¡ æ˜¾å­˜ä¼˜åŒ–å·²å¯ç”¨ï¼Œç”Ÿæˆé€Ÿåº¦ä¼šå˜æ…¢ã€‚"
    CMD_STEP4+=" --enable_cpu_offload"
fi

if [ -n "$GEN_LIMIT" ]; then
    echo "ğŸŸ¡ ä½¿ç”¨å­é›†ç”Ÿæˆæ¨¡å¼: åªç”Ÿæˆå‰ $GEN_LIMIT ä¸ªæ ·æœ¬"
    CMD_STEP4+=" --limit \"$GEN_LIMIT\""
fi

run_step "Â§4. å›¾åƒç”Ÿæˆ (ç»Ÿä¸€å¼•æ“)" "$GEN_IMAGES_DIR" "$CMD_STEP4"

# --- Â§5 è¯„æµ‹ ---
# 5.1 æ‰“åŒ…ç”Ÿæˆç»“æœçš„ç‰¹å¾
if [ ! -d "${EXP_DIR}/images" ]; then
    echo "ğŸŸ¡ åˆ›å»ºæŒ‡å‘ç”Ÿæˆå›¾åƒç›®å½•çš„ç¬¦å·é“¾æ¥: ${EXP_DIR}/images -> ${GEN_IMAGES_DIR}"
    ln -s "${GEN_IMAGES_DIR}" "${EXP_DIR}/images" || true
fi
mkdir -p "${EXP_DIR}/eval_results"

CMD_STEP5_1="bash -c '${PY_INFER} \"${PROJ_ROOT}/tools/pack_recons.py\" --infer_dir \"${EXP_DIR}\" && mv -f \"${EXP_DIR}/recons.pt\" \"${RECONS_PT}\" || true; mkdir -p \"${EXP_DIR}/eval_results\"; if [ -f \"${EXP_DIR}/ids.json\" ]; then mv -f \"${EXP_DIR}/ids.json\" \"${EXP_DIR}/eval_results/recons_ids.json\"; fi'"
run_step "Â§5.1 è¯„æµ‹: æ‰“åŒ…ç”Ÿæˆå›¾åƒçš„ç‰¹å¾" "$RECONS_PT" "$CMD_STEP5_1"

# 5.2 è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡
CMD_STEP5_2="${PY_INFER} \"${PROJ_ROOT}/tools/eval_recons.py\" \
    --model_dir \"${EXP_DIR}\" \
    --gt_images \"${GT_EMBEDS_PT}\""
run_step "Â§5.2 è¯„æµ‹: è®¡ç®—æ ¸å¿ƒè¯„æµ‹æŒ‡æ ‡" "$METRICS_JSON" "$CMD_STEP5_2"

# --- æœ€ç»ˆæ€»ç»“ ---
echo "============================================================"
echo "ğŸ‰ æ¨ç†æµç¨‹å…¨éƒ¨å®Œæˆï¼"
echo "============================================================"

TOTAL_END_TIME=$(date +%s)
TOTAL_DURATION=$((TOTAL_END_TIME - TOTAL_START_TIME))

echo "æœ€ç»ˆç”Ÿæˆçš„å›¾åƒä½äº: ${GEN_IMAGES_DIR}"
echo "æœ€ç»ˆçš„è¯„æµ‹æŒ‡æ ‡ä½äº: ${METRICS_JSON}"

echo ""
echo "============================================================"
echo "â±ï¸  æ—¶é—´ç»Ÿè®¡æŠ¥å‘Š"
echo "============================================================"

format_time() {
    local total_seconds=$1
    local hours=$((total_seconds / 3600))
    local minutes=$(((total_seconds % 3600) / 60))
    local seconds=$((total_seconds % 60))
    
    if [ $hours -gt 0 ]; then
        printf "%då°æ—¶%dåˆ†%dç§’" $hours $minutes $seconds
    elif [ $minutes -gt 0 ]; then
        printf "%dåˆ†%dç§’" $minutes $seconds
    else
        printf "%dç§’" $seconds
    fi
}

step_num=0
for step_name in "${STEP_NAMES[@]}"; do
    step_num=$((step_num + 1))
    case $step_num in
        1) step_key="1" ;;
        2) step_key="2" ;;
        3) step_key="3" ;;
        4) step_key="4" ;;
        5) step_key="5.1" ;;
        6) step_key="5.2" ;;
        *) step_key="$step_num" ;;
    esac
    
    duration=${STEP_TIMES[$step_key]:-0}
    formatted_time=$(format_time $duration)
    
    if [ $duration -eq 0 ]; then
        echo "ğŸ“Š ${step_name}: ${formatted_time} (è·³è¿‡)"
    else
        echo "ğŸ“Š ${step_name}: ${formatted_time}"
    fi
done

echo ""
echo "ğŸ• æ€»æ‰§è¡Œæ—¶é—´: $(format_time $TOTAL_DURATION)"

if [ $TOTAL_DURATION -gt 0 ]; then
    echo ""
    echo "ğŸ“ˆ æ—¶é—´åˆ†å¸ƒ:"
    step_idx=0
    for step_name in "${STEP_NAMES[@]}"; do
        step_idx=$((step_idx + 1))
        case $step_idx in
            1) step_key="1" ;;
            2) step_key="2" ;;
            3) step_key="3" ;;
            4) step_key="4" ;;
            5) step_key="5.1" ;;
            6) step_key="5.2" ;;
            *) step_key="$step_idx" ;;
        esac
        
        duration=${STEP_TIMES[$step_key]:-0}
        if [ $duration -gt 0 ]; then
            percentage=$((duration * 100 / TOTAL_DURATION))
            echo "   ${step_name}: ${percentage}%"
        fi
    done
fi

echo ""
echo "æ‚¨å¯ä»¥æŸ¥çœ‹è¯„æµ‹æ–‡ä»¶ä»¥è·å–é‡åŒ–ç»“æœ:"
echo "cat ${METRICS_JSON}"
echo "============================================================"
