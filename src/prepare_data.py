import h5py
import numpy as np
import os
import csv
from tqdm import tqdm

# ==================================
# 1. é…ç½®å‚æ•°
# ==================================
# è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆè¯·ç¡®ä¿è¿™äº›æ–‡ä»¶ä¸è„šæœ¬åœ¨åŒä¸€ç›®å½•ï¼Œæˆ–ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
IMAGES_HDF5_PATH = 'coco_images_224_float16.hdf5'
ANNOTS_NPY_PATH = 'subj01_annots.npy'

# è¾“å‡ºæ–‡ä»¶å
OUTPUT_CSV_PATH = 'train_pairs_subj01.csv'

# è¢«è¯•ID
SUBJECT_ID = 'subj01'

# ==================================
# 2. ä¸»é€»è¾‘ï¼šç”ŸæˆCSVæ–‡ä»¶
# ==================================
def create_training_csv():
    """
    åŠ è½½æ•°æ®ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªç”¨äºè®­ç»ƒæ–‡æœ¬é€‚é…å™¨çš„CSVæ–‡ä»¶ã€‚
    """
    print(f"\n{'='*60}")
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆè®­ç»ƒæ•°æ®CSVæ–‡ä»¶...")
    print(f"{'='*60}")

    # --- æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ ---
    if not os.path.exists(IMAGES_HDF5_PATH):
        print(f"âŒ é”™è¯¯: å›¾åƒæ–‡ä»¶æœªæ‰¾åˆ° -> {IMAGES_HDF5_PATH}")
        return
    if not os.path.exists(ANNOTS_NPY_PATH):
        print(f"âŒ é”™è¯¯: æ ‡æ³¨æ–‡ä»¶æœªæ‰¾åˆ° -> {ANNOTS_NPY_PATH}")
        return
    
    print("âœ… è¾“å…¥æ–‡ä»¶æ£€æŸ¥é€šè¿‡ã€‚")

    # --- åŠ è½½æ•°æ® ---
    print("ğŸ“¦ æ­£åœ¨åŠ è½½æ ‡æ³¨æ–‡ä»¶...")
    captions = np.load(ANNOTS_NPY_PATH, allow_pickle=True)
    num_captions = len(captions)
    print(f"   - æˆåŠŸåŠ è½½ {num_captions} æ¡æ–‡æœ¬æè¿°ã€‚")

    print("ğŸ“¦ æ­£åœ¨æ‰“å¼€å›¾åƒHDF5æ–‡ä»¶...")
    with h5py.File(IMAGES_HDF5_PATH, 'r') as hf:
        num_images = len(hf['images'])
        print(f"   - HDF5æ–‡ä»¶ä¸­åŒ…å« {num_images} å¼ å›¾åƒã€‚")

    # --- å†³å®šæ•°æ®é›†å¤§å° ---
    dataset_size = min(num_captions, num_images)
    if num_captions != num_images:
        print(f"âš ï¸ è­¦å‘Š: æ–‡æœ¬å’Œå›¾åƒæ•°é‡ä¸åŒ¹é…ã€‚å°†ä½¿ç”¨è¾ƒå°çš„å€¼: {dataset_size}")
    else:
        print(f"âœ… æ–‡æœ¬å’Œå›¾åƒæ•°é‡åŒ¹é…: {dataset_size}")

    # --- å†™å…¥CSVæ–‡ä»¶ ---
    print(f"\nâœï¸ æ­£åœ¨å°† {dataset_size} æ¡è®°å½•å†™å…¥åˆ° {OUTPUT_CSV_PATH}...")
    
    # å®šä¹‰CSVæ–‡ä»¶çš„è¡¨å¤´
    fieldnames = ['subject_id', 'prompt', 'neg_prompt', 'gt_image_path', 'ip_embed_path']
    
    try:
        with open(OUTPUT_CSV_PATH, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            # å†™å…¥è¡¨å¤´
            writer.writeheader()
            
            # ä½¿ç”¨tqdmåˆ›å»ºè¿›åº¦æ¡ï¼Œé€è¡Œå†™å…¥æ•°æ®
            for i in tqdm(range(dataset_size), desc="ç”ŸæˆCSVä¸­"):
                # è·å–å½“å‰è¡Œçš„æ–‡æœ¬æè¿°
                prompt_text = captions[i]
                
                # æ„é€ ä¸€è¡Œæ•°æ®
                # æ³¨æ„ï¼šgt_image_path å’Œ ip_embed_path æˆ‘ä»¬æš‚æ—¶ç•™ç©ºæˆ–ä½¿ç”¨å ä½ç¬¦
                # å› ä¸ºæˆ‘ä»¬çš„è®­ç»ƒè„šæœ¬å¯ä»¥ç›´æ¥ä»HDF5ä¸­æŒ‰ç´¢å¼•è¯»å–å›¾åƒï¼Œ
                # ä½†ä¸ºäº†ä¸ä½ çš„éª¨æ¶ä»£ç å…¼å®¹ï¼Œæˆ‘ä»¬å…ˆåˆ›å»ºè¿™ä¸ªåˆ—ã€‚
                row = {
                    'subject_id': SUBJECT_ID,
                    'prompt': prompt_text,
                    'neg_prompt': '',  # è´Ÿé¢æç¤ºæš‚æ—¶ç•™ç©º
                    'gt_image_path': f'hdf5_index_{i}', # ä½¿ç”¨ç´¢å¼•ä½œä¸ºå ä½ç¬¦
                    'ip_embed_path': '' # IP-AdapteråµŒå…¥è·¯å¾„æš‚æ—¶ç•™ç©º
                }
                
                # å†™å…¥è¿™ä¸€è¡Œ
                writer.writerow(row)
                
        print(f"\nğŸ‰ æˆåŠŸï¼CSVæ–‡ä»¶å·²ç”Ÿæˆ: {OUTPUT_CSV_PATH}")
        print(f"   - æ€»è®¡å†™å…¥ {dataset_size} è¡Œæ•°æ®ã€‚")
        print(f"   - æ–‡ä»¶æ ¼å¼: {', '.join(fieldnames)}")

    except Exception as e:
        print(f"\nâŒ åœ¨å†™å…¥CSVæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    print(f"\n{'='*60}")
    print(f"âœ… æ•°æ®å‡†å¤‡å·¥ä½œå®Œæˆï¼")
    print(f"{'='*60}\n")


# ==================================
# 3. ç¨‹åºå…¥å£
# ==================================
if __name__ == '__main__':
    create_training_csv()

